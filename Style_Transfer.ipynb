{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Style_Transfer_Demo.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harish203201/Deep-Learning/blob/master/Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciYyUYVZT4IA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "style_image_path = \"index2.jpg\"\n",
        "content_image_path = \"IMG_20200805_134456_278.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyENTFmggM19",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def load_img(path_to_img, dimension):\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img = img[tf.newaxis, :]\n",
        "  shape = tf.cast(tf.shape(img)[1:-1], tf.float32)\n",
        "  short_dim = min(shape)\n",
        "  scale = dimension / short_dim\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "  image = tf.image.resize(img, new_shape)\n",
        "  image = tf.image.resize_with_crop_or_pad(image, dimension, dimension)\n",
        "  return image\n",
        "\n",
        "content_image = load_img(content_image_path, 384)\n",
        "style_image = load_img(style_image_path, 256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUDZZN7Gxaz3",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')\n",
        "style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBNjdwyXlx_B",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import array_to_img\n",
        "content_blending_ratio = 0.2 \n",
        "\n",
        "def run_style_predict(preprocessed_style_image):\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_predict_path)\n",
        "  interpreter.allocate_tensors()\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_style_image)\n",
        "  interpreter.invoke()\n",
        "  style_bottleneck = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "      )()\n",
        "  return style_bottleneck\n",
        "\n",
        "style_bottleneck = run_style_predict(style_image)\n",
        "\n",
        "def run_style_transform(style_bottleneck, preprocessed_content_image):\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_transform_path)\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.allocate_tensors()\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_content_image)\n",
        "  interpreter.set_tensor(input_details[1][\"index\"], style_bottleneck)\n",
        "  interpreter.invoke()\n",
        "  stylized_image = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "      )()\n",
        "\n",
        "  return stylized_image\n",
        "\n",
        "style_bottleneck_content = run_style_predict(\n",
        "    load_img(content_image_path, 256)\n",
        ")\n",
        "style_bottleneck_blended = content_blending_ratio * style_bottleneck_content + (1 - content_blending_ratio) * style_bottleneck\n",
        "stylized_image = run_style_transform(style_bottleneck_blended, content_image)\n",
        "array_to_img(stylized_image.squeeze(axis=0)).save(\"stylized_image.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}